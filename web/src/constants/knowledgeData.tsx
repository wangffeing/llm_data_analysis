import React from 'react';
import {
  BarChartOutlined,
  LineChartOutlined,
  EyeOutlined,
  NodeIndexOutlined,
  RocketOutlined,
  BulbOutlined,
  DatabaseOutlined,
  ToolOutlined,
  CheckCircleOutlined,
  ThunderboltOutlined,
  PhoneOutlined,
  HeartOutlined,
  FundProjectionScreenOutlined,
  WifiOutlined,
  ExperimentOutlined, // 新增：高级统计分析方法图标
  RobotOutlined // 新增：机器学习模型选择指南图标
} from '@ant-design/icons';
import { Descriptions } from 'antd';

// #region --- 类型定义 (为更丰富的数据结构更新) ---
export interface TermDefinition {
  term: string;
  definition: string;
  example?: string;
  formula?: string;
  caution?: string; // 新增：慎用提醒
}

export interface ModelDetail {
  name: string;
  desc: string; // 描述（含优缺点）
}

export interface MethodDetail {
  name: string;
  description: string;
  scenarios?: string; // 新增：适用场景
  models?: ModelDetail[] | string[]; // 支持更复杂的模型结构
}

export interface PracticeDetail {
    title: string;
    detail: string;
}

export const analysisMethodsKnowledge = {
  descriptive: {
    title: '描述性分析 (发生了什么?) ”',
    Descriptions: '用诸如均值、中位数、标准差等统计指标，结合柱状图、箱线图、散点图等可视化手段，对数据的整体分布、集中与波动情况进行快速扫面。不仅能立刻看出主要趋势和潜在异常，还能通过帕累托和 RFM 分析，精准定位对结果影响最大的关键因素。',
    icon: <BarChartOutlined />,
    methods: [
      { name: '集中与离散趋势分析', description: '计算均值、中位数、标准差、四分位距等，快速了解数据的基本面貌。', scenarios: '适用于所有分析的起点，用于数据概览和质量检验。' },
      { name: '可视化探索', description: '通过图表直观发现数据模式。常用图表：柱状图、折线图、饼图、箱线图、散点图、热力图、地理空间图等。', scenarios: '所有分析的初期阶段，用于快速洞察数据、验证假设。' },
      { name: '帕累托分析 (80/20法则)', description: '找出导致大部分问题（或贡献大部分价值）的关键少数因素。', scenarios: '分析哪些产品贡献了80%的销售额；哪些类型的投诉占了80%的总量。' },
      { name: 'RFM分析', description: '通过最近一次消费(Recency)、消费频率(Frequency)、消费金额(Monetary)三个维度对客户进行价值细分。', scenarios: '客户关系管理(CRM)中，用于识别高价值客户、沉睡客户、流失风险客户等。' },
    ]
  },
  diagnostic: {
    title: '诊断性分析 (为什么会发生?)',
    Descriptions: '发现了异常或关键波动后，需要深入挖掘根本驱动因素。通过鱼骨图与“五个为什么”法分层剖析，用漏斗模型量化流程各环节的流失，用多渠道归因评估不同推广路径的实际贡献，并通过层层下钻定位到具体区域或产品线，以便形成可执行的改进方案。',
    icon: <EyeOutlined />,
    methods: [
      { name: '根本原因分析 (RCA)', description: '通过鱼骨图、5 Whys等方法，层层深入，探究问题（如“接通率下降”）发生的根本原因。', scenarios: '适用于KPI指标异常波动、生产事故、项目延期等问题的深度回溯。' },
      { name: '漏斗分析', description: '分析用户在转化路径（如“注册->下单->支付”）中每一步的流失情况，定位关键瓶颈。', scenarios: '电商用户转化、App用户注册流程优化、市场活动效果评估。' },
      { name: '归因分析', description: '确定多个营销渠道（如SEO、广告、社交媒体）对最终转化结果的贡献度。', scenarios: '评估广告投放ROI、优化市场预算分配、了解渠道协同效应。' },
      { name: '下钻分析 (Drill-Down)', description: '将宏观数据逐层分解，深入到更细的维度进行观察，以定位问题或机会。', scenarios: '从“全国销售额下降”下钻到“某地区-某城市-某门店”的销售情况。' }
    ]
  },
  correlation: {
    title: '相关性与因果分析 (变量间是什么关系？)',
    Descriptions: '先用皮尔逊和斯皮尔曼系数量化连续与排序变量间的线性或单调关联，再通过 t 检验、卡方检验等方法判断分组差异的显著性。若要进一步确认“因果”，则引入双重差分、工具变量或断点回归技术，有效剥离混杂因素，逼近真实的因果效应。',
    icon: <NodeIndexOutlined />,
    methods: [
      { name: '皮尔逊相关系数', description: '衡量两个连续变量之间线性关系的强度和方向（-1到1）。注意：相关不等于因果！', scenarios: '分析“广告投入”与“销售额”的关系；“等待时长”与“客户满意度”的关系。' },
      { name: '斯皮尔曼等级相关', description: '衡量两个变量（可以是定序变量）之间单调关系的强度，对异常值不敏感。', scenarios: '分析“教育水平等级”与“收入等级”的关系。' },
      { name: '因果推断', description: '使用双重差分(DID)、工具变量(IV)、断点回归(RD)等高级方法，在非实验数据中剥离混杂因素，探究变量间的因果关系。', scenarios: '评估政策实施效果、分析新功能上线对用户留存的真实影响。' },
    ]
  },
  trend: {
    title: '趋势与对比分析 (如何变化？)',
    Descriptions: '把时间维度拆成趋势、季节和残差，既能看清数据的长期走向，也能捕捉周期性波动；同比和环比则帮助你在不同时间尺度上做精准对比；再辅以 A/B 测试或多维分组对比，你既能洞察整体变化，又能评估具体策略或人群的差异表现。',
    icon: <LineChartOutlined />,
    methods: [
        { 
        name: '时间序列分析', 
        description: '分析指标随时间的变化趋势、周期性和季节性。', 
        scenarios: '分析月度销售额变化趋势，识别年度季节性波动；监控网站日活跃用户数的长期增长或下降趋势。' 
        },
        { 
        name: '同比与环比分析', 
        description: '与历史同期（同比）或上一周期（环比）对比，消除季节性影响。', 
        scenarios: '分析本月销售额环比增长5%，但同比下降2%，表明整体增长可能面临压力；比较本周与上周的用户新增数。' 
        },
        { 
        name: 'A/B测试', 
        description: '通过随机实验，科学地对比不同策略或方案的效果差异。', 
        scenarios: '测试新旧两个版本的登录页面，哪个能带来更高的注册转化率；比较两种不同的推荐算法对用户点击率的影响。' 
        },
        { 
        name: '卡方检验', 
        description: '检验两个分类变量之间是否存在显著关联。', 
        scenarios: '分析用户性别与偏好的产品类型之间是否存在关联；检验不同地区的客户投诉类型分布是否一致。' 
        },
    ]
    },
  mlModels: {
    title: '预测性分析 (将要发生什么?)',
    Descriptions: '基于前面各阶段提炼出的特征和洞察，构建回归、分类、聚类、降维及深度学习等模型，对未来数值、类别或隐藏模式进行预测。模型输出不仅包含预期值，还常附带置信区间或风险评估，助力决策者在不确定环境中制定更可靠的行动方案。',
    icon: <RocketOutlined />,
    methods: [
      {
        name: '回归模型 (Regression)',
        description: '核心思想：拟合一个函数来预测一个连续的数值型输出。主要应用：销量预测、房价预测、金融风险评估。',
        models: [
          { name: '线性回归', desc: '优点: 简单、易于解释; 缺点: 对非线性关系和异常值敏感。' },
          { name: '岭回归/Lasso回归', desc: '优点: 在线性回归基础上增加正则化，可防止过拟合，Lasso还能做特征选择。' },
          { name: '泊松回归', desc: '优点: 专门用于预测“计数”类型的数据（如一小时内来电次数）。' },
          { name: '梯度提升回归 (GBRT)', desc: '优点: 精度高，能处理非线性关系和交互特征; 缺点: 训练慢，可解释性差。' }
        ]
      },
      {
        name: '分类模型 (Classification)',
        description: '核心思想：学习一个决策边界来预测一个离散的类别标签。主要应用：客户流失预警、垃圾邮件识别、图像识别。',
        models: [
            { name: '逻辑回归', desc: '优点: 速度快，可解释性强（输出概率）; 缺点: 易欠拟合，对非线性特征表达能力弱。' },
            { name: '朴素贝叶斯', desc: '优点: 在文本分类上表现优异，对小样本友好; 缺点: “朴素”的特征独立假设在现实中往往不成立。' },
            { name: '随机森林', desc: '优点: 精度高，抗过拟合能力强; 缺点: 模型较大，可解释性弱于单棵决策树。' },
            { name: 'XGBoost/LightGBM', desc: '优点: 目前业界公认的精度高、速度快的“大杀器”; 缺点: 参数多，调参复杂。' },
        ]
      },
      {
        name: '聚类与关联规则模型',
        description: '核心思想：在无标签数据中发现内在结构与模式。',
        models: [
            { name: 'K-均值 (K-Means)', desc: '优点: 速度快，简单有效; 缺点: 需预先指定簇数量K，对初始点和异常值敏感。' },
            { name: 'DBSCAN', desc: '优点: 能发现任意形状的簇，对异常值不敏感; 缺点: 对密度参数敏感。' },
            { name: '关联规则 (Apriori)', desc: '优点: 能发现项集之间的有趣关系（如“啤酒与尿布”）; 缺点: 在大数据集上计算量巨大。' },
        ]
      },
      {
        name: '降维模型 (Dimensionality Reduction)',
        description: '核心思想：在保留大部分信息的同时，减少数据中的特征数量。主要应用：数据可视化、特征提取、去噪。',
        models: [
            { name: '主成分分析 (PCA)', desc: '优点: 无监督，计算速度快; 缺点: 可解释性差，新特征是原特征的线性组合。' },
            { name: 't-SNE', desc: '优点: 在高维数据可视化方面效果极佳; 缺点: 计算量大，主要用于可视化而非聚类。' },
        ]
      },
      {
        name: '深度学习模型 (Deep Learning)',
        description: '核心思想：通过构建深层神经网络，自动学习数据的高阶抽象特征。',
        models: [
            { name: 'ANN/DNN', desc: '人工/深度神经网络，是所有深度学习模型的基础，适用于结构化数据。' },
            { name: 'CNN (卷积神经网络)', desc: '优点: 在图像识别、计算机视觉领域处于统治地位。' },
            { name: 'RNN/LSTM/GRU', desc: '优点: 能处理序列数据，在自然语言处理（NLP）和时间序列预测中表现出色。' },
            { name: 'Transformer', desc: '优点: 基于自注意力机制，已成为现代NLP（如BERT, GPT）和越来越多其他领域的主流架构。' },
        ]
      }
    ]
  },
  advancedStatistics: {
    title: '高级统计分析方法',
    Descriptions: '当业务问题需要更严谨的统计推断时，引入假设检验（如 t 检验、ANOVA、卡方）、多元与正则化回归、ARIMA/Prophet/LSTM 等时间序列模型、生存分析及贝叶斯推断等高级技术。这些方法能在小样本、高维度或删失数据等复杂场景下，提供更精细、更可靠的结论。',
    icon: <ExperimentOutlined />,
    methods: [
      {
        name: '假设检验 (Hypothesis Testing)',
        description: '通过样本数据对总体参数进行推断，判断假设是否成立。包括t检验、方差分析(ANOVA)、卡方检验等。',
        scenarios: '验证新功能是否显著提升用户留存率；检验不同地区销售额是否存在显著差异；A/B测试结果的统计显著性验证。',
        models: [
          { name: '单样本t检验', desc: '检验样本均值是否等于某个特定值。适用于样本量较小且总体标准差未知的情况。' },
          { name: '双样本t检验', desc: '比较两个独立样本的均值是否相等。常用于A/B测试的效果评估。' },
          { name: '配对t检验', desc: '比较同一组对象在两种条件下的表现差异。如用户使用新旧系统前后的满意度对比。' },
          { name: '方差分析(ANOVA)', desc: '同时比较三个或更多组别的均值差异。可进一步分解为组间方差和组内方差。' },
          { name: '卡方检验', desc: '检验分类变量之间的独立性或拟合优度。如性别与产品偏好是否相关。' }
        ]
      },
      {
        name: '回归分析进阶',
        description: '超越简单线性回归，处理复杂的变量关系、多重共线性、异方差等问题。',
        scenarios: '分析多个因素对销售额的综合影响；处理存在交互效应的变量关系；解决预测变量间相关性过高的问题。',
        models: [
          { name: '多元线性回归', desc: '同时考虑多个自变量对因变量的影响。需注意多重共线性问题。' },
          { name: '逐步回归', desc: '自动选择最优的变量组合，包括前向选择、后向剔除、双向逐步等方法。' },
          { name: '岭回归(Ridge)', desc: '通过L2正则化解决多重共线性问题，适用于变量数量较多的情况。' },
          { name: 'Lasso回归', desc: '通过L1正则化实现变量选择和系数收缩，可自动剔除不重要的变量。' },
          { name: '弹性网络(Elastic Net)', desc: '结合Ridge和Lasso的优点，在变量选择和处理相关变量组方面表现优异。' }
        ]
      },
      {
        name: '时间序列分析',
        description: '专门分析按时间顺序排列的数据，识别趋势、季节性、周期性等时间模式。',
        scenarios: '预测未来销售额；分析股价走势；监控系统性能指标的异常波动；识别业务的季节性规律。',
        models: [
          { name: 'ARIMA模型', desc: '自回归积分滑动平均模型，是时间序列预测的经典方法。适用于平稳时间序列。' },
          { name: '季节性分解', desc: '将时间序列分解为趋势、季节性和随机成分，便于理解各成分的贡献。' },
          { name: '指数平滑', desc: '给近期数据更高权重的预测方法，包括简单、双重、三重指数平滑。' },
          { name: 'Prophet模型', desc: 'Facebook开源的时间序列预测工具，能自动处理节假日效应和趋势变化点。' },
          { name: 'LSTM时间序列', desc: '基于深度学习的长短期记忆网络，能捕捉复杂的非线性时间依赖关系。' }
        ]
      },
      {
        name: '生存分析 (Survival Analysis)',
        description: '分析事件发生的时间，特别适用于处理删失数据（如客户流失、设备故障等）。',
        scenarios: '分析客户生命周期和流失风险；预测设备故障时间；评估医疗治疗效果；分析员工离职模式。',
        models: [
          { name: 'Kaplan-Meier估计', desc: '非参数方法估计生存函数，能处理删失数据，直观展示生存概率随时间的变化。' },
          { name: 'Cox比例风险模型', desc: '半参数模型，分析多个因素对生存时间的影响，无需假设特定的生存分布。' },
          { name: 'Log-rank检验', desc: '比较两个或多个组别的生存曲线是否存在显著差异。' },
          { name: '参数生存模型', desc: '假设特定分布（如威布尔、指数）的生存模型，可提供更精确的参数估计。' }
        ]
      },
      {
        name: '贝叶斯统计',
        description: '基于贝叶斯定理的统计推断方法，能融合先验知识和观测数据，提供概率性的结论。',
        scenarios: '在小样本情况下进行推断；融合专家经验和数据证据；不确定性量化；动态更新预测模型。',
        models: [
          { name: '贝叶斯线性回归', desc: '提供参数的概率分布而非点估计，能量化预测的不确定性。' },
          { name: 'MCMC采样', desc: '马尔可夫链蒙特卡罗方法，用于复杂贝叶斯模型的参数估计。' },
          { name: '贝叶斯网络', desc: '用有向无环图表示变量间的概率依赖关系，适用于因果推理和决策支持。' },
          { name: '变分推断', desc: '贝叶斯推断的近似方法，计算效率高于MCMC，适用于大规模数据。' }
        ]
      }
    ]
  },
  modelSelection: {
    title: '机器学习模型选择指南',
    Descriptions: '根据任务类型（分类、回归、聚类等）、数据规模、特征复杂度和对可解释性的要求，从朴素贝叶斯、决策树、XGBoost 到深度学习框架，给出合理的模型匹配建议；同时指导如何制定交叉验证策略、选择评估指标，并针对常见应用场景（客户流失、推荐系统、图像/文本处理、异常检测）提供最佳实践。',
    icon: <RobotOutlined />,
    methods: [
      {
        name: '问题类型识别',
        description: '根据业务目标和数据特征，正确识别机器学习问题的类型，这是模型选择的第一步。',
        scenarios: '项目启动阶段的问题定义；数据科学团队技术方案设计；向业务方解释技术可行性。',
        models: [
          { name: '监督学习', desc: '有标签数据，目标是学习输入到输出的映射关系。包括分类（预测类别）和回归（预测数值）。' },
          { name: '无监督学习', desc: '无标签数据，目标是发现数据中的隐藏模式。包括聚类、降维、关联规则挖掘等。' },
          { name: '半监督学习', desc: '部分数据有标签，利用无标签数据提升模型性能。适用于标注成本高的场景。' },
          { name: '强化学习', desc: '通过与环境交互学习最优策略。适用于游戏AI、推荐系统、自动驾驶等动态决策场景。' },
          { name: '迁移学习', desc: '利用在相关任务上训练的模型知识，加速新任务的学习。常用于深度学习领域。' }
        ]
      },
      {
        name: '数据规模与复杂度匹配',
        description: '根据数据量大小、特征维度、计算资源等因素选择合适复杂度的模型。',
        scenarios: '评估项目的计算资源需求；在模型精度和训练时间间做权衡；处理大规模数据的技术选型。',
        models: [
          { name: '小数据集(<1K样本)', desc: '推荐：朴素贝叶斯、线性模型、KNN。避免：深度学习、复杂集成模型。' },
          { name: '中等数据集(1K-100K)', desc: '推荐：随机森林、SVM、梯度提升。可尝试：浅层神经网络。' },
          { name: '大数据集(>100K)', desc: '推荐：XGBoost/LightGBM、深度学习。考虑：分布式训练、在线学习算法。' },
          { name: '高维数据', desc: '推荐：正则化线性模型(Lasso/Ridge)、随机森林。注意：维度灾难、特征选择。' },
          { name: '实时预测需求', desc: '推荐：线性模型、决策树。避免：复杂集成模型、深度学习（除非有专门优化）。' }
        ]
      },
      {
        name: '可解释性需求评估',
        description: '根据业务对模型解释性的要求，在模型精度和可解释性之间找到平衡点。',
        scenarios: '金融风控模型的监管要求；医疗诊断的决策支持；向业务方解释模型预测结果。',
        models: [
          { name: '高可解释性', desc: '线性回归、逻辑回归、决策树。优点：结果易理解；缺点：可能精度较低。' },
          { name: '中等可解释性', desc: '随机森林、梯度提升树。可通过特征重要性、SHAP值等方法增强解释性。' },
          { name: '低可解释性', desc: '深度学习、SVM（非线性核）。精度高但难以解释，需要额外的解释性工具。' },
          { name: '事后解释方法', desc: 'LIME、SHAP、注意力机制等。为黑盒模型提供局部或全局解释。' }
        ]
      },
      {
        name: '模型评估与选择策略',
        description: '建立科学的模型评估体系，避免过拟合，确保模型在真实环境中的表现。',
        scenarios: '模型上线前的最终评估；多个候选模型的对比选择；模型性能的持续监控。',
        models: [
          { name: '交叉验证', desc: 'K折交叉验证是标准做法。时间序列数据需使用时间序列交叉验证。' },
          { name: '评估指标选择', desc: '分类：准确率、精确率、召回率、F1、AUC；回归：MAE、MSE、MAPE；排序：NDCG、MAP。' },
          { name: '业务指标对齐', desc: '技术指标需与业务KPI对齐。如推荐系统的点击率vs用户满意度。' },
          { name: '模型集成', desc: 'Bagging、Boosting、Stacking等方法组合多个模型，通常能提升性能。' },
          { name: 'AutoML工具', desc: 'H2O.ai、AutoKeras等自动化机器学习工具，可快速筛选和优化模型。' }
        ]
      },
      {
        name: '特定场景的模型推荐',
        description: '针对常见的业务场景，提供经过验证的模型选择建议和最佳实践。',
        scenarios: '快速启动新项目；借鉴行业最佳实践；避免重复试错。',
        models: [
          { name: '客户流失预测', desc: '推荐：逻辑回归、随机森林、XGBoost。关注：样本不平衡、特征工程、时间窗口设计。' },
          { name: '推荐系统', desc: '协同过滤、矩阵分解、深度学习(DeepFM、Wide&Deep)。考虑：冷启动、实时性、多样性。' },
          { name: '时间序列预测', desc: 'ARIMA、Prophet、LSTM。注意：季节性、趋势变化、外部因素。' },
          { name: '文本分类', desc: 'TF-IDF+朴素贝叶斯、Word2Vec+CNN、BERT等预训练模型。' },
          { name: '图像识别', desc: 'CNN架构：ResNet、EfficientNet。考虑：迁移学习、数据增强、模型压缩。' },
          { name: '异常检测', desc: 'Isolation Forest、One-Class SVM、Autoencoder。处理：样本极度不平衡。' }
        ]
      }
    ]
  }
};
// #endregion

// #region --- 2. 数据分析术语库 (深度扩充) ---
export const generalDataAnalysisTerms: Record<string, TermDefinition[]> = {
  '基础统计': [
    { 
      term: '均值 (Mean)', 
      definition: '数据集中所有数值的总和除以数值的个数，易受极端值影响。', 
      formula: 'x̄ = (Σx_i) / n'
    },
    { 
      term: '中位数 (Median)', 
      definition: '将数据集排序后，位于最中间的数值，对极端值不敏感。如果数据量为偶数，则为中间两个数的平均值。', 
      formula: '若 n 为奇数: Med = x_((n+1)/2)；若 n 为偶数: Med = (x_(n/2) + x_(n/2 + 1)) / 2'
    },
    { 
      term: '众数 (Mode)', 
      definition: '数据集中出现频率最高的数值。一个数据集可以有多个众数（多峰）或没有众数。', 
      formula: 'Mode = { x_i | count(x_i) = max(count(x_j)) }'
    },
    { 
      term: '标准差 (Standard Deviation)', 
      definition: '衡量数据集中各个数据点相对于均值的离散程度。值越大，数据越分散。样本标准差使用n-1进行无偏估计。', 
      formula: 's = √[ Σ(x_i - x̄)² / (n - 1) ]'
    },
    { 
      term: '方差 (Variance)', 
      definition: '标准差的平方，是衡量数据离散程度的另一个核心指标。', 
      formula: 's² = Σ(x_i - x̄)² / (n - 1)'
    },
    { 
      term: '极差 (Range)', 
      definition: '数据集中的最大值与最小值之差，是衡量离散程度最简单但最不稳健的指标。', 
      formula: 'R = max(x_i) - min(x_i)'
    },
    { 
      term: '四分位距 (IQR)', 
      definition: '第三四分位数(Q3)与第一四分位数(Q1)之差，衡量了中间50%数据的离散程度，对异常值不敏感，是箱线图的核心。', 
      formula: 'IQR = Q₃ - Q₁'
    },
    { 
      term: '偏度 (Skewness)', 
      definition: '衡量数据分布不对称性的指标。正偏态（右偏）表示右侧尾部更长，负偏态（左偏）反之。0表示对称分布。', 
      formula: 'Skewness = [ Σ(x_i - x̄)³ / n ] / [ (Σ(x_i - x̄)² / n)^(3/2) ]'
    },
    { 
      term: '峰度 (Kurtosis)', 
      definition: '衡量数据分布陡峭或平坦程度的指标。与正态分布（峰度为3）相比，高耸的分布具有正峰度（>3），平坦的分布具有负峰度（<3）。通常使用“超额峰度”（峰度-3），使正态分布的超额峰度为0。', 
      formula: 'Kurtosis = [ Σ(x_i - x̄)⁴ / n ] / [ (Σ(x_i - x̄)² / n)² ]'
    },
    { 
      term: '协方差 (Covariance)', 
      definition: '衡量两个变量共同变化的趋势。正值表示同向变化，负值表示反向变化。其数值大小受变量量纲影响，因此常用相关系数进行标准化。', 
      formula: 'Cov(X,Y) = Σ(x_i - x̄)(y_i - ȳ) / (n - 1)'
    },
    { 
      term: '皮尔逊相关系数 (Pearson Correlation Coefficient)', 
      definition: '协方差经标准化后的结果，衡量两个连续变量之间的线性相关强度和方向，取值范围在-1到1之间。', 
      formula: 'r = Cov(X,Y) / (s_X * s_Y) = Σ(x_i - x̄)(y_i - ȳ) / [ √Σ(x_i - x̄)² * √Σ(y_i - ȳ)² ]'
    },
    { 
      term: 'z-分数 (z-Score)', 
      definition: '将原始数据标准化，表示一个数据点距离均值有多少个标准差。常用于异常值检测和不同量纲数据的比较。', 
      formula: 'z = (x - x̄) / s'
    },
    { 
      term: '百分位数 (Percentile)', 
      definition: '表示数据集中有p%的数据小于或等于该数值。例如，第95百分位数表示有95%的数据点低于此值。', 
      formula: 'P_p = value below which p% of the observations may be found'
    }
  ],
  '数据质量与处理': [
    { 
      term: '数据清洗 (Data Cleaning)', 
      definition: '识别并修正（或删除）数据中的错误、不一致或不准确的部分，是确保分析结果可靠性的基础步骤。', 
      example: '将“北京市”和“北京”统一为标准名称；修正因录入错误导致的“出生日期”为2050年的情况。', 
      caution: '清洗过程需谨慎，避免误删有效数据或引入新的偏见。所有清洗操作都应有记录和可追溯性。'
    },
    { 
      term: '缺失值 (Missing Value)', 
      definition: '数据集中不存在或未记录的数据点。其产生原因可能是数据未被采集、系统故障或用户未填写等。', 
      example: '客户信息表中，部分用户的“邮箱地址”字段为空。', 
      caution: '直接删除含有缺失值的记录可能导致样本偏差（尤其当缺失是非随机时）。选择填充方法（均值、中位数、众数、模型预测）需结合数据类型和业务背景。'
    },
    { 
      term: '异常值 (Outlier)', 
      definition: '与数据集中其他数据点显著不同的数据点。可能是录入错误、测量误差，也可能是真实的极端情况（如VIP客户消费）。', 
      example: '在分析“用户月消费”时，大部分用户在100-500元之间，但有一个用户消费了10万元。', 
      caution: '切勿简单粗暴地删除所有异常值。应先分析其成因：如果是错误，则修正或删除；如果是真实业务现象，则需保留，并考虑其对模型（如线性回归）的影响，或使用对异常值不敏感的模型（如决策树）。'
    },
    { 
      term: '特征工程 (Feature Engineering)', 
      definition: '利用领域知识从原始数据中创建更能代表问题本质、从而提升模型性能的新特征的过程。', 
      example: '从“订单创建时间”和“订单完成时间”计算出“订单处理时长”；将连续的“年龄”分箱为“青年”、“中年”、“老年”等类别。', 
      caution: '特征工程是提升模型性能的关键，但也最耗时。需警惕“过拟合”风险，确保新特征具有合理的业务解释，避免构造仅在训练集上有效的“魔法特征”。'
    },
    { 
      term: '分箱/离散化 (Binning)', 
      definition: '将连续变量划分为若干个区间（或“箱”），并用区间标签（如“低”、“中”、“高”）或区间中位数来表示，以处理非线性关系和减少异常值影响。', 
      formula: '例如，将年龄 [0,18) -> "未成年", [18,60) -> "成年", [60, ∞) -> "老年"', 
      caution: '分箱会丢失原始数据的精确信息。分箱的数量和边界选择（等宽、等频、基于业务规则）对结果影响很大，需仔细考量。'
    },
    { 
      term: '数据泄露 (Data Leakage)', 
      definition: '在训练模型时，使用了在实际预测时不可能获取到的信息，导致模型评估性能虚高，但在真实环境中表现极差。', 
      example: '在预测客户是否会流失时，使用了“客户注销日期”作为特征（因为流失的客户才有注销日期，这在预测时是未知的）。', 
      caution: '这是建模中最严重的错误之一。必须严格区分“训练时可用信息”和“预测时可用信息”，并在特征工程和数据处理的每一步都进行检查。'
    },
    // --- 新增术语 ---
    { 
      term: '数据标准化/归一化 (Standardization/Normalization)', 
      definition: '将不同量纲或范围的特征缩放到一个统一的尺度，以确保模型（尤其是基于距离的模型如K-Means、SVM）不会因某个特征数值过大而主导结果。', 
      example: '将“年龄”（0-100）和“年薪”（0-100万）都缩放到0-1范围或均值为0、标准差为1的分布。', 
      caution: '标准化(Z-score)适用于特征分布近似正态的情况；归一化(Min-Max)会将所有数据压缩到[0,1]，对异常值敏感。缩放的参数（如均值、标准差、最大最小值）必须仅从训练集计算，然后应用到测试集。'
    },
    { 
      term: '数据偏斜 (Data Skewness)', 
      definition: '指数据分布严重偏离正态分布，通常表现为长尾分布。许多统计模型和机器学习算法在正态分布假设下表现更佳。', 
      example: '用户消费金额、网站访问时长等数据通常呈现右偏（正偏）分布，即大部分值较小，少数极高值拉长了右侧尾巴。', 
      caution: '高度偏斜的数据会影响模型性能。可通过对数变换、平方根变换等方法缓解偏斜，使分布更接近正态。'
    },
    { 
      term: '重复数据 (Duplicate Data)', 
      definition: '数据集中存在完全相同或高度相似的多条记录，通常是由于数据合并、系统故障或重复采集造成。', 
      example: '同一个客户因系统错误被记录了两条完全相同的订单信息。', 
      caution: '重复数据会扭曲统计分析结果（如总销售额被高估）和模型训练（模型会过度关注重复样本）。识别和去重是数据清洗的重要环节，但需注意“完全相同”和“业务上视为同一实体”的区别。'
    },
    { 
      term: '数据一致性 (Data Consistency)', 
      definition: '指数据在不同系统、不同时间或不同记录之间保持逻辑上的正确和统一。', 
      example: 'CRM系统中客户的“当前套餐”应与计费系统中的“当前套餐”保持一致；“订单总金额”应等于所有“商品单价*数量”的总和。', 
      caution: '数据不一致是“数据孤岛”的常见问题，会导致分析结论矛盾。需要建立数据校验规则和主数据管理(MDM)机制。'
    },
    { 
      term: '数据时效性 (Data Timeliness)', 
      definition: '指数据反映现实世界状态的新鲜程度。过时的数据可能导致错误的决策。', 
      example: '用于实时风控的用户行为数据延迟了1小时，可能导致风险事件无法被及时拦截。', 
      caution: '并非所有分析都需要实时数据。需根据业务场景（实时监控 vs. 月度报告）明确对数据延迟的容忍度，并确保数据管道能满足SLA（服务等级协议）。'
    }
  ],
  '实验设计': [
    { 
      term: 'A/B测试', 
      definition: '一种随机实验，通过将用户随机分配到对照组(A)和实验组(B)，比较两个版本在给定指标上的表现差异，以科学地评估产品改动的效果。', 
      example: '测试新旧两个版本的登录按钮颜色，哪个能带来更高的点击率。', 
      caution: '必须确保用户分组是随机的，且两组用户特征在统计上无显著差异。实验期间避免同时进行其他可能影响结果的改动。'
    },
    { 
      term: 'P值 (p-value)', 
      definition: '在原假设（通常指“两组无差异”）为真的前提下，观察到当前样本差异或更极端差异的概率。是判断统计显著性的核心指标。', 
      example: 'A/B测试结果显示P值为0.03，意味着在两组确实无差异的假设下，出现当前或更极端结果的概率仅为3%。', 
      caution: 'P值不能告诉我们效应的大小或实际重要性，也不能直接给出原假设为假的概率。要警惕P值篡改（p-hacking），即通过不断尝试不同分组或指标直到得到显著结果。'
    },
    { 
      term: '置信水平/置信区间', 
      definition: '置信水平（如95%）表示我们有多大信心认为真实参数值（如两组转化率的差值）落在计算出的置信区间内。置信区间给出了效应大小的可能范围。', 
      example: '测得实验组比对照组转化率高5%，95%置信区间为[2%, 8%]，表示我们有95%的信心认为真实提升在2%到8%之间。', 
      caution: '置信区间不包含0是判断统计显著性的一种方式（等价于P<0.05）。但即使区间不包含0，如果范围很宽（如[1%, 15%]），也说明估计不够精确。'
    },
    { 
      term: '统计显著性', 
      definition: '当P值小于预设的显著性水平α（通常为0.05）时，我们称结果具有统计显著性。这意味着观察到的效应不太可能是由随机偶然造成的。', 
      example: '在α=0.05的水平下，P=0.01的结果是统计显著的，我们可以拒绝“两组无差异”的原假设。', 
      caution: '统计显著不等于实际显著。一个微小的、无实际意义的提升也可能因为样本量巨大而变得“统计显著”。决策时应结合效应大小和业务背景。'
    },
    // --- 新增术语 ---
    { 
      term: '功效 (Statistical Power)', 
      definition: '在备择假设为真（即两组确实存在差异）的情况下，实验能够正确检测出这种差异的概率。通常希望功效达到80%以上。', 
      example: '设计一个A/B测试前，通过功效分析计算出需要至少10,000名用户才能以80%的概率检测出5%的转化率提升。', 
      caution: '功效不足的实验（样本量太小）很容易得出“无显著差异”的结论，但这可能是因为实验没能力发现真实存在的效应（假阴性），而非效应不存在。'
    },
    { 
      term: '效应量 (Effect Size)', 
      definition: '衡量实验组和对照组之间差异大小的标准化指标，与P值不同，它不受样本量影响，更能反映实际意义。', 
      example: "除了报告转化率提升了3%，还应报告Cohen's d值为0.4，表示这是一个中等程度的效应。", 
      caution: '仅报告P值是不充分的。应同时报告效应量和置信区间，以全面评估实验结果的实际价值。'
    },
    { 
      term: '多重比较问题 (Multiple Comparisons)', 
      definition: '当同时进行多次假设检验（如测试多个页面元素或多个用户分群）时，整体犯第一类错误（假阳性）的概率会显著增加。', 
      example: '同时对标题、图片、按钮颜色进行A/B测试，共3个检验。即使每个检验的α=0.05，整体犯错的概率远高于5%。', 
      caution: '需要使用校正方法（如Bonferroni校正）来控制整体错误率，或预先设定一个主要指标，次要指标作为参考。'
    },
    { 
      term: '实验分组 (Random Assignment)', 
      definition: '将用户或实验单元随机分配到不同组的过程，是保证A/B测试有效性的基石，旨在消除混杂变量的影响。', 
      example: '使用用户的唯一ID进行哈希运算，根据哈希值的奇偶性将用户随机分入A组或B组。', 
      caution: '需确保分组逻辑是稳定和可复现的。要检查分组后各组的关键指标（如用户数量、历史活跃度）是否均衡。'
    },
    { 
      term: '新奇效应 (Novelty Effect)', 
      definition: '用户因为对新功能感到新鲜而暂时性地增加使用，这种效应会随时间衰减，可能导致实验初期结果被高估。', 
      example: '上线新UI后，用户活跃度短期内飙升，但几周后回落到正常水平。', 
      caution: '应延长实验周期，让新奇效应充分衰减后再评估最终效果。避免在功能刚上线时就急于下结论。'
    },
    { 
      term: '学习效应 (Learning Effect)', 
      definition: '用户需要时间学习和适应新功能，初期表现可能不佳，这种效应会随时间改善。', 
      example: '引入复杂的新操作流程后，用户初期的错误率和完成时长增加，但经过一段时间后熟练度提高，效率提升。', 
      caution: '对于需要用户学习的功能，实验周期应足够长，以捕捉到用户适应后的稳定表现。'
    }
  ],
  '机器学习基础': [
    { 
      term: '集成学习 (Ensemble Learning)', 
      definition: '组合多个“弱学习器”来构建一个“强学习器”的方法，通常能获得比单个模型更好的泛化性能和鲁棒性。主要分为Bagging、Boosting和Stacking。', 
      example: '随机森林（Bagging）和XGBoost（Boosting）都是集成学习的成功应用。', 
      caution: '虽然性能强大，但集成模型通常更复杂、训练更慢、且可解释性更差。应根据问题的复杂性和对解释性的要求进行权衡。'
    },
    { 
      term: 'Bagging (Bootstrap Aggregating)', 
      definition: '通过有放回抽样（Bootstrap）生成多个训练子集，独立训练多个基模型，最后通过投票（分类）或平均（回归）来整合结果，有效降低模型的方差。', 
      example: '随机森林是Bagging思想的典型应用，它使用决策树作为基模型，并在特征选择上也进行随机化。', 
      caution: 'Bagging主要解决高方差问题（过拟合），对高偏差问题（欠拟合）效果有限。'
    },
    { 
      term: 'Boosting (提升法)', 
      definition: '串行地训练一系列基模型，每个新模型都专注于学习前一个模型的“残差”（预测错误），通过加权求和的方式组合所有模型，有效降低模型的偏差。', 
      example: 'AdaBoost、梯度提升机(GBM)、XGBoost、LightGBM都是Boosting的著名实现。', 
      caution: '由于模型是串行训练的，Boosting对训练数据中的噪声和异常值更敏感，容易过拟合。需要仔细调整学习率等参数。'
    },
    { 
      term: '偏差-方差权衡 (Bias-Variance Tradeoff)', 
      definition: '机器学习模型预测误差的两个主要来源。偏差高意味着模型过于简单，无法捕捉数据的复杂模式（欠拟合）；方差高意味着模型过于复杂，过度拟合了训练数据中的噪声（过拟合）。', 
      example: '一个简单的线性回归模型可能偏差高（欠拟合），而一个深度过大的决策树可能方差高（过拟合）。', 
      caution: '我们的目标是找到一个偏差和方差都较低的平衡点。交叉验证是评估模型泛化能力、指导此权衡的有效工具。'
    },
    { 
      term: '强化学习 (Reinforcement Learning)', 
      definition: '一种机器学习范式，智能体(Agent)通过与环境(Env)交互，根据其采取的行动(Action)获得的奖励(Reward)来学习最优策略(Policy)，以最大化长期累积奖励。', 
      example: 'AlphaGo下围棋、机器人路径规划、游戏AI、动态定价系统。', 
      caution: '强化学习通常需要大量的交互和试错，训练过程可能不稳定。在现实世界的商业应用中，设计合理的奖励函数和模拟环境是巨大挑战。'
    },
    // --- 新增术语 ---
    { 
      term: '过拟合 (Overfitting)', 
      definition: '模型在训练集上表现极好，但在未见过的测试集或真实数据上表现很差的现象。原因是模型学习了训练数据中的噪声和随机波动，而非其内在规律。', 
      example: '一个模型在训练集上准确率达到99%，但在测试集上只有60%，这很可能是过拟合。', 
      caution: '这是机器学习中最常见的问题之一。可通过增加训练数据、简化模型、使用正则化（L1/L2）、Dropout（深度学习）、交叉验证等方法来缓解。'
    },
    { 
      term: '欠拟合 (Underfitting)', 
      definition: '模型在训练集和测试集上都表现不佳的现象。原因是模型过于简单，不足以捕捉数据的基本模式和关系。', 
      example: '用一条直线去拟合一组呈明显二次曲线分布的数据，结果无论在训练还是测试数据上，拟合度都很差。', 
      caution: '解决方案包括使用更复杂的模型、进行更丰富的特征工程、减少正则化强度等。'
    },
    { 
      term: '交叉验证 (Cross-Validation)', 
      definition: '一种评估模型泛化能力的统计方法，通过将数据集划分为K个子集，轮流将K-1个子集作为训练集，剩下的1个作为验证集，重复K次，最终取K次性能的平均值。', 
      example: '5折交叉验证是评估模型性能和选择超参数的常用方法，比简单的“训练-测试”分割更稳健。', 
      caution: '对于时间序列数据，应使用时间序列交叉验证，避免未来信息泄露到训练集。分层K折交叉验证(Stratified K-Fold)能保证每个子集中各类别的比例与原数据集一致，对分类问题很重要。'
    },
    { 
      term: '正则化 (Regularization)', 
      definition: '在模型的损失函数中加入一个惩罚项，以限制模型的复杂度，防止过拟合。L1正则化（Lasso）倾向于产生稀疏解（特征选择），L2正则化（Ridge）倾向于让权重更小更平滑。', 
      example: '在逻辑回归中添加L2正则化项，可以防止某些特征的权重过大。', 
      caution: '正则化强度（λ）是一个关键的超参数，需要通过交叉验证来选择。强度过小则不起作用，过大则可能导致欠拟合。'
    },
    { 
      term: '超参数 (Hyperparameter)', 
      definition: '在模型训练开始前需要手动设定的参数，它们不是通过训练数据学习得到的。例如：决策树的最大深度、K-Means的簇数量K、学习率、正则化系数等。', 
      example: '在使用XGBoost时，`max_depth` 和 `learning_rate` 都是需要调优的超参数。', 
      caution: '超参数的选择对模型性能影响巨大。通常使用网格搜索、随机搜索或贝叶斯优化等方法进行调优。'
    },
    { 
      term: '梯度下降 (Gradient Descent)', 
      definition: '一种用于优化模型参数的迭代算法。其核心思想是计算损失函数关于模型参数的梯度（偏导数），然后沿着梯度的反方向更新参数，以逐步最小化损失函数。', 
      example: '线性回归和神经网络的训练过程都依赖于梯度下降或其变体（如随机梯度下降SGD、Adam）。', 
      caution: '学习率的选择至关重要：过大可能导致无法收敛，过小则收敛速度慢。对于非凸函数，可能陷入局部最优解。'
    }
  ],
  '模型评估指标': [
    { 
      term: '混淆矩阵 (Confusion Matrix)', 
      definition: '一个2x2表格，用于可视化二分类模型的性能，是计算其他指标的基础。包含真正例(TP)、假正例(FP)、真负例(TN)、假负例(FN)四个基本元素。', 
      caution: '对于多分类问题，混淆矩阵会扩展为n x n矩阵，分析更为复杂。'
    },
    { 
      term: '精确率 (Precision) & 召回率 (Recall)', 
      definition: '一对相互制约的指标。精确率(Precision) = TP / (TP + FP)，关注“查得准不准”；召回率(Recall) = TP / (TP + FN)，关注“查得全不全”。', 
      example: '在垃圾邮件识别中，高精确率意味着被标记为垃圾邮件的邮件中，绝大多数确实是垃圾邮件；高召回率意味着绝大多数真正的垃圾邮件都被成功识别。', 
      caution: '两者通常此消彼长。选择哪个更重要取决于业务场景。在反欺诈中，可能更看重召回率（不漏掉坏人）；在推荐系统中，可能更看重精确率（不打扰用户）。'
    },
    { 
      term: 'F1分数 (F1-Score)', 
      definition: '精确率和召回率的调和平均数，提供了一个单一的综合评分。F1 = 2 * (Precision * Recall) / (Precision + Recall)。当精确率和召回率都很重要时，F1分数是一个很好的评估指标。', 
      example: '在客户流失预警中，我们既希望准确识别出所有可能流失的客户（高召回率），又不希望对大量不会流失的客户进行不必要的打扰（高精确率），此时F1分数是理想的评估指标。', 
      caution: 'F1分数对精确率和召回率的权重是相等的。如果两者的重要性不同，可以使用Fβ分数进行加权。'
    },
    { 
      term: 'ROC曲线 & AUC', 
      definition: 'ROC曲线以假正率(FPR)为横轴，真正率(TPR/Recall)为纵轴绘制。AUC (Area Under Curve) 是ROC曲线下的面积，衡量分类器在所有可能阈值上的综合性能，值越接近1越好。', 
      example: 'AUC=0.9表示模型有很强的判别能力，能很好地区分正负样本。', 
      caution: 'AUC对类别不平衡问题相对鲁棒，但当负样本数量远多于正样本时，PR曲线（精确率-召回率曲线）和AUPRC（PR曲线下面积）可能是更好的评估标准。'
    },
    { 
      term: '调整后R方 (Adjusted R-squared)', 
      definition: '在R方的基础上，对自变量的数量进行了惩罚。公式为：1 - [(1-R²)(n-1)/(n-p-1)]，其中n是样本量，p是自变量数量。在多元回归中，当添加无用变量时，R方会增加，但调整后R方可能会下降。', 
      example: '一个模型的R²从0.85提升到0.86，但调整后R²从0.83下降到0.82，说明新增的变量对模型的解释力提升有限，且增加了模型复杂度。', 
      caution: '应优先关注调整后R方，尤其是在比较不同数量自变量的回归模型时。'
    },
    { 
      term: '均方误差 (MSE) & 均方根误差 (RMSE)', 
      definition: 'MSE是预测值与真实值之差的平方的平均值。RMSE是MSE的平方根，其单位与原始数据相同，更易于解释。两者都是回归模型最常用的损失函数和评估指标，值越小越好。', 
      formula: 'MSE = Σ(y_i - ŷ_i)² / n; RMSE = √MSE', 
      caution: 'MSE/RMSE对异常值非常敏感，一个很大的预测误差会被平方放大。如果数据中存在异常值，可以考虑使用平均绝对误差(MAE)。'
    },
    { 
      term: '平均绝对误差 (MAE)', 
      definition: '预测值与真实值之差的绝对值的平均数。MAE = Σ|y_i - ŷ_i| / n。', 
      example: 'MAE=100元意味着模型预测的平均误差是100元。', 
      caution: 'MAE对异常值不敏感，能提供更稳健的误差估计。但因为它不放大误差，所以在优化时可能不如MSE有效。'
    },
    { 
      term: '轮廓系数 (Silhouette Coefficient)', 
      definition: '衡量聚类效果的指标，值在-1到1之间。它综合了簇内紧密度和簇间分离度。越接近1表示聚类效果越好（簇内紧密，簇间分离）；接近0表示样本在两个簇的边界上；为负值表示样本可能被分到了错误的簇。', 
      example: '通过比较不同K值（簇数量）下的平均轮廓系数，可以帮助选择最优的K值。', 
      caution: '轮廓系数在簇为凸形时表现良好，但对于非凸形状的簇（如环形），其评估效果可能不佳。'
    },
    // --- 新增术语 ---
    { 
      term: '对数损失 (Log Loss)', 
      definition: '用于评估分类模型输出概率的好坏。它惩罚那些置信度很高但预测错误的样本。预测概率越接近真实标签（0或1），损失越小。', 
      formula: 'Log Loss = - (1/n) Σ [y_i * log(ŷ_i) + (1-y_i) * log(1-ŷ_i)]', 
      caution: '对数损失要求模型输出的是概率，而非硬分类。它是逻辑回归等模型的默认损失函数，也是评估概率校准性的重要指标。'
    },
    { 
      term: '平均精度均值 (mAP)', 
      definition: 'Mean Average Precision，是目标检测和信息检索领域的核心评估指标。它首先计算每个类别的平均精度(AP)，然后对所有类别的AP取平均。综合考虑了精确率和召回率。', 
      example: '在图像识别中，mAP是衡量模型检测出所有目标并准确定位的综合能力的标准。', 
      caution: 'mAP的计算相对复杂，通常依赖于IoU（交并比）阈值。不同的IoU阈值会产生不同的mAP结果。'
    },
    { 
      term: '基尼不纯度 (Gini Impurity)', 
      definition: '决策树算法中用于衡量数据集纯度的指标。值越小，数据集越“纯”（即样本都属于同一类别）。在节点分裂时，会选择能最大程度降低基尼不纯度的特征和分裂点。', 
      formula: 'Gini = 1 - Σ(p_i)²', 
      caution: '另一种衡量纯度的指标是“信息熵(Entropy)”，两者在实践中效果相近，基尼不纯度计算更快。'
    }
  ],
    '常见机器学习模型': [
    { 
      term: '线性回归', 
      definition: '一种基础的回归模型，假设目标变量与一个或多个特征之间存在线性关系。通过最小化预测值与真实值之间的平方误差来拟合一条直线或超平面。', 
      example: '预测房价（目标变量）基于房屋面积、房间数量等特征。', 
      caution: '对异常值敏感，假设线性关系，在非线性问题上表现不佳。'
    },
    { 
      term: '逻辑回归', 
      definition: '一种用于二分类问题的广义线性模型。它使用Sigmoid函数将线性回归的输出映射到(0,1)区间，输出可以解释为属于某一类别的概率。', 
      example: '根据用户的年龄、收入等信息，预测其是否会购买某个产品。', 
      caution: '本质上是线性分类器，对非线性决策边界无能为力。'
    },
    { 
      term: '支持向量机 (SVM)', 
      definition: '一种强大的监督学习算法，核心思想是寻找一个最优的超平面，以最大化两个类别之间的间隔（Margin）。通过核函数可以有效处理非线性分类问题。', 
      example: '在高维特征空间中进行图像分类或文本分类。', 
      caution: '对特征缩放和超参数（如C、gamma）非常敏感，训练时间在大数据集上可能很长。'
    },
    { 
      term: '决策树', 
      definition: '一种树形结构的模型，通过一系列“if-then”规则进行决策。易于理解和解释，能处理数值型和类别型特征。', 
      example: '根据“年龄”、“收入”、“信用评分”等条件判断是否批准贷款。', 
      caution: '容易过拟合，对训练数据的小幅变动不稳健。'
    },
    { 
      term: '随机森林', 
      definition: '一种集成学习方法，通过构建多棵决策树（使用Bootstrap抽样和特征随机选择）并对其结果进行投票或平均，来提高模型的准确性和鲁棒性。', 
      example: '在金融风控中预测用户违约风险。', 
      caution: '模型可解释性较差，预测速度可能慢于单棵决策树。'
    },
    { 
      term: '梯度提升机 (GBM)', 
      definition: '一种集成学习方法，通过串行地训练一系列弱学习器（通常是决策树），每一棵新树都专注于修正前一棵树的残差，最终将所有树的结果加权求和。', 
      example: 'Kaggle竞赛中常用的高精度模型。', 
      caution: '训练速度慢，对超参数非常敏感，容易过拟合。'
    },
    { 
      term: 'XGBoost', 
      definition: 'GBM的一个高效、可扩展的实现，通过正则化、并行计算和近似算法，显著提升了训练速度和模型性能。', 
      example: '大规模结构化数据的回归和分类问题。', 
      caution: '参数众多，调参复杂。'
    },
    { 
      term: 'LightGBM', 
      definition: '微软开发的梯度提升框架，采用基于直方图的决策树算法和Leaf-wise生长策略，在处理大规模数据时速度和内存效率远超XGBoost。', 
      example: '大数据集上的点击率预测、推荐系统。', 
      caution: '在小数据集上可能过拟合。'
    },
    { 
      term: 'K-均值 (K-Means)', 
      definition: '一种经典的无监督聚类算法，通过迭代将数据划分为K个簇，使得每个数据点到其所属簇中心的距离平方和最小。', 
      example: '对客户进行分群，以便进行精准营销。', 
      caution: '需要预先指定K值，对初始中心点和异常值敏感。'
    },
    { 
      term: '主成分分析 (PCA)', 
      definition: '一种无监督的降维技术，通过线性变换将原始特征转换为一组新的、互不相关的主成分，这些主成分按解释方差的大小排序。', 
      example: '将高维数据降至2维或3维以便于可视化。', 
      caution: '主成分是原始特征的线性组合，可解释性较差。'
    },
    { 
      term: '卷积神经网络 (CNN)', 
      definition: '一种深度学习模型，特别适用于处理具有网格结构的数据，如图像。通过卷积层自动提取局部特征（如边缘、纹理），并利用池化层降低维度。', 
      example: '图像识别、人脸识别、医学影像分析。', 
      caution: '需要大量数据和计算资源进行训练。'
    },
    { 
      term: '循环神经网络 (RNN)', 
      definition: '一种深度学习模型，具有“记忆”功能，其神经元的输出会反馈到输入，使其能够处理序列数据（如文本、语音、时间序列）。', 
      example: '自然语言处理（如机器翻译）、语音识别、时间序列预测。', 
      caution: '存在梯度消失/爆炸问题，难以学习长距离依赖。'
    },
    { 
      term: '长短期记忆网络 (LSTM)', 
      definition: 'RNN的一种特殊变体，通过引入“门”（遗忘门、输入门、输出门）机制，有效解决了标准RNN的梯度消失问题，能够学习长期依赖关系。', 
      example: '股票价格预测、文本生成、机器翻译。', 
      caution: '结构比标准RNN复杂，训练时间更长。'
    },
    { 
      term: 'Transformer', 
      definition: '一种基于“自注意力机制”(Self-Attention)的深度学习架构，完全摒弃了RNN的循环结构，能够并行处理序列中的所有元素，从而极大提升了训练效率。', 
      example: '现代大语言模型（如BERT, GPT系列）的基础架构。', 
      caution: '模型参数量巨大，需要海量数据和强大的算力。'
    }
  ]

};

export const telecomTerms: Record<string, TermDefinition[]> = {
  '通信行业专业术语': [
    { term: '接通率', definition: '成功接通的呼叫数量占总呼叫数量的百分比', example: '某客服中心日接通率为95%，表示100个来电中有95个成功接通' },
    { term: '首次解决率 (FCR)', definition: '客户问题在首次联系时就得到完全解决的比例', example: 'FCR为80%意味着10个客户中有8个在第一次通话中解决了问题' },
    { term: '平均处理时长 (AHT)', definition: '客服代表处理一个客户问题所需的平均时间', example: 'AHT为5分钟，包括通话时间和后续处理时间' },
    { term: '客户满意度 (CSAT)', definition: '客户对服务质量满意程度的量化指标', example: 'CSAT评分4.2/5.0，表示客户整体满意度较高' },
    { term: '话务量 (Call Volume)', definition: '在特定时间段内接收到的呼叫总数', example: '高峰期话务量达到每小时1000通，需要合理安排人员' },
    { term: '放弃率 (Abandonment Rate)', definition: '客户在等待过程中主动挂断的呼叫比例', example: '放弃率为5%，表示每100个来电中有5个客户等待时放弃' },
    { term: '服务水平 (Service Level)', definition: '在规定时间内应答呼叫的百分比', example: '服务水平80/20表示80%的呼叫在20秒内得到应答' },
    { term: '平均等待时长 (AWT)', definition: '客户从拨打电话到与客服代表接通的平均等待时间', example: '平均等待时长为30秒，超过1分钟客户满意度明显下降' }
  ]
};
export const allTerms = { general: generalDataAnalysisTerms, telecom: telecomTerms };
// #endregion

// #region --- 3. CRISP-DM 最佳实践 (深度扩充) ---
export const bestPracticesData: { stage: string; icon: React.ReactNode; practices: PracticeDetail[] }[] = [
  {
    stage: '1. 业务理解 (Business Understanding)',
    icon: <BulbOutlined />,
    practices: [
        { title: '定义SMART问题', detail: '确保你的分析问题是具体的(Specific)、可衡量的(Measurable)、可实现的(Achievable)、相关的(Relevant)和有时限的(Time-bound)。' },
        { title: '明确交付成果与成功标准', detail: '与业务方确认最终需要交付什么（如报告、仪表盘、模型API），以及如何评判项目成功（如“将流失率降低2%”）。' },
        { title: '进行成本效益分析', detail: '初步评估项目所需的数据、人力和时间成本，以及它可能带来的业务价值，判断项目可行性。' },
    ],
  },
  {
    stage: '2. 数据理解 (Data Understanding)',
    icon: <DatabaseOutlined />,
    practices: [
        { title: '建立数据字典', detail: '为每个关键字段创建文档，说明其定义、数据类型、取值范围、业务含义和更新频率。这是团队协作和知识传承的基础。' },
        { title: '进行探索性数据分析(EDA)', detail: '使用统计摘要和可视化图表，对数据进行初步探索，以发现模式、异常和变量间的关系，形成初步假设。' },
        { title: '验证数据质量', detail: '系统性地检查数据的准确性、完整性、一致性、时效性和唯一性。' },
    ],
  },
  {
    stage: '3. 数据准备 (Data Preparation)',
    icon: <ToolOutlined />,
    practices: [
        { title: '制定清晰的数据处理流程', detail: '记录所有数据清洗、转换、特征工程的步骤，最好通过代码实现，以保证流程的可复现性。' },
        { title: '特征工程要有创造性', detail: '结合业务知识，构造有意义的衍生变量，如从用户行为日志中提取“最近购买间隔”、“平均会话时长”等。' },
        { title: '严防数据泄露', detail: '确保任何数据处理（如标准化、填充）和特征选择，都只使用训练集的信息，然后将相同的转换应用到验证集和测试集。' },
    ],
  },
  {
    stage: '4. 模型构建 (Modeling)',
    icon: <RocketOutlined />,
    practices: [
        { title: '从基线模型开始', detail: '先建立一个非常简单的模型（如平均值预测、逻辑回归）作为基准，任何复杂模型的性能都应优于它。' },
        { title: '使用交叉验证', detail: '在中小数据集上，使用K折交叉验证来更稳健地评估模型性能和选择超参数，避免因单次划分带来的偶然性。' },
        { title: '版本控制', detail: '对训练代码、模型参数和最终生成的模型文件进行版本管理（如使用Git和DVC），确保实验的可追溯性。' },
    ],
  },
  {
    stage: '5. 模型评估 (Evaluation)',
    icon: <CheckCircleOutlined />,
    practices: [
        { title: '结合业务场景选择指标', detail: '在不同的业务场景下，精确率和召回率的重要性不同。例如，在反欺诈中，召回率（不漏掉坏人）可能更重要。' },
        { title: '评估模型的公平性与鲁棒性', detail: '检查模型在不同人群或数据子集上是否存在偏见，并测试其在面对数据小幅扰动时的稳定性。' },
        { title: '进行错误分析', detail: '深入分析模型预测错误的样本，了解模型“错在哪里”，这往往是下一步优化的灵感来源。' },
    ],
  },
  {
    stage: '6. 部署与沟通 (Deployment & Communication)',
    icon: <ThunderboltOutlined />,
    practices: [
        { title: '用故事化的方式呈现结果', detail: '将你的分析发现组织成一个有开头、发展和结尾的故事，而不是罗列图表和数字。' },
        { title: '结论先行，提供证据', detail: '在汇报时，先给出最重要的结论，然后展示支撑该结论的数据证据。' },
        { title: '制定模型监控计划', detail: '模型部署后，需要持续监控其性能和输入数据的分布，以应对“模型衰减”问题，并适时进行再训练。' },
    ],
  },
];
export const telecomBusinessScenarios = {
  customerService: {
    title: '客服中心运营',
    icon: <PhoneOutlined />,
    scenarios: [
      {
        name: '务量预测与智能排班',
        description: '基于历史话务量数据，精准预测未来（如未来1小时、1天、1周）的呼入量，并结合客服技能、成本等因素，自动生成最优排班方案。',
        keyMetrics: ['话务量', '预测准确率(MAPE)', '接通率', '平均等待时长', '人员利用率', '人力成本'],
        analysisSteps: [
          '收集并整合多维度历史数据（按小时/天/周的话务量、节假日、促销活动、天气等）。',
          '通过时间序列分析（如ARIMA, Prophet）识别话务量的趋势、周期性和季节性特征。',
          '建立话务量预测模型，并持续监控和迭代模型。',
          '将预测结果输入到排班优化算法中，生成满足服务水平且成本最优的排班表。'
        ],
        expectedOutcome: '在保障服务水平（如80/20）的前提下，最小化人力成本，避免人员冗余或短缺。'
      },
      {
        name: '服务质量监控与改进',
        description: '监控关键服务指标，识别问题并制定改进措施',
        keyMetrics: ['一次解决率', '客户满意度', '平均通话时长', '投诉率'],
        analysisSteps: [
          '建立服务质量指标监控体系',
          '分析指标变化趋势和异常波动',
          '识别影响服务质量的关键因素',
          '对比不同客服代表的绩效表现',
          '制定针对性的培训和改进计划'
        ],
        expectedOutcome: '提升整体服务质量，增强客户满意度'
      }
    ]
  },
  customerExperience: {
    title: '客户体验优化',
    icon: <HeartOutlined />,
    scenarios: [
      {
        name: '客户流失预警与干预',
        description: '基于客户的行为、消费和交互数据，构建机器学习模型，预测未来可能流失的客户，并分析其主要特征，以便进行精准挽留。',
        keyMetrics: ['客户流失率', '模型预测准确率/召回率', '用户活跃度(DAU/MAU)', '近期消费频率', '投诉次数'],
        analysisSteps: [
          '定义明确的流失标准（如“连续90天无任何消费或登录”）。',
          '整合客户全方位数据，构建特征工程（如“近30天通话次数”、“平均套餐消费”等）。',
          '使用分类模型（如逻辑回归、XGBoost）训练流失预警模型。',
          '对高流失风险的客户进行画像分析，找出共性原因（如“高套餐低用量”、“近期多次投诉”）。',
          '针对不同原因的流失风险客户，推送个性化的挽留策略（如优惠券、套餐升级提醒、专属客服关怀）。'
        ],
        expectedOutcome: '从被动响应变为主动干预，精准定位高危流失客户，降低客户流失率，提升客户生命周期总价值(LTV)。'
      },
      {
        name: '客户旅程分析',
        description: '分析客户在服务过程中的完整体验路径',
        keyMetrics: ['各环节耗时', '流失率', '满意度', '转化率'],
        analysisSteps: [
          '梳理客户服务的完整流程',
          '收集各环节的数据和客户反馈',
          '分析客户在各环节的行为和体验',
          '识别体验痛点和改进机会',
          '设计优化方案并验证效果'
        ],
        expectedOutcome: '优化客户体验，提高客户忠诚度'
      },
      {
        name: '客户细分与个性化服务',
        description: '基于客户特征和行为进行细分，提供个性化服务',
        keyMetrics: ['客户价值', '服务偏好', '满意度', '留存率'],
        analysisSteps: [
          '收集客户基本信息和行为数据',
          '使用RFM模型等方法进行客户细分',
          '分析不同客户群体的特征和需求',
          '设计差异化的服务策略',
          '评估个性化服务的效果'
        ],
        expectedOutcome: '提高服务精准度，增强客户价值'
      },
      {
        name: '客户分群与精准营销',
        description: '使用聚类算法对客户进行细分，形成具有相似特征和行为模式的客群，从而实现差异化的服务和营销策略。',
        keyMetrics: ['客户价值(RFM)', '用户画像标签', '营销活动转化率', 'ARPU值'],
        analysisSteps: [
          '选择合适的客户分群维度，如RFM（最近一次消费、消费频率、消费金额）、人口属性、行为偏好等。',
          '应用K-Means等聚类算法进行客户分群。',
          '为每个客群进行画像，总结其典型特征（如“高价值商务男”、“价格敏感学生族”）。',
          '针对不同客群设计并推送个性化的产品、服务或营销活动。',
          '通过A/B测试评估不同营销策略对各客群的效果。'
        ],
        expectedOutcome: '提升营销资源的利用效率和转化率，增强客户满意度和忠诚度。'
      }

    ]
  },
  businessIntelligence: {
    title: '业务智能分析',
    icon: <FundProjectionScreenOutlined />,
    scenarios: [
      {
        name: '运营效率分析',
        description: '分析客服中心的运营效率，识别改进机会',
        keyMetrics: ['人均处理量', '成本效率', '资源利用率', '自动化率'],
        analysisSteps: [
          '建立运营效率指标体系',
          '收集人员、设备、系统的运营数据',
          '分析效率瓶颈和改进空间',
          '对比行业标杆和最佳实践',
          '制定效率提升计划'
        ],
        expectedOutcome: '提高运营效率，降低运营成本'
      },
      {
        name: '业务趋势预测',
        description: '基于历史数据预测业务发展趋势',
        keyMetrics: ['业务量增长', '成本变化', '收入预测', '市场份额'],
        analysisSteps: [
          '收集历史业务数据和外部环境数据',
          '分析业务发展的驱动因素',
          '建立预测模型和情景分析',
          '评估不同策略的影响',
          '制定业务发展规划'
        ],
        expectedOutcome: '支持战略决策，优化资源配置'
      }
    ]
  },
  networkOptimization: {
    title: '网络优化与规划',
    icon: <WifiOutlined />,
    scenarios: [
      {
        name: '网络覆盖与质量分析',
        description: '基于地理位置和网络信令数据，分析网络覆盖盲区和弱信号区域，诊断网络质量问题。',
        keyMetrics: ['信号强度(RSRP)', '信号质量(SINR)', '掉线率', '接入成功率'],
        analysisSteps: [
          '融合用户上报的地理位置和网络质量数据。',
          '使用地理信息系统(GIS)将网络指标在地图上进行可视化。',
          '通过聚类算法识别网络质量差的区域簇。',
          '关联区域内的基站负载、干扰等信息，诊断问题根源。',
          '为基站扩容或新建站提供数据支持。'
        ],
        expectedOutcome: '精准定位网络问题，提升用户网络体验，指导网络投资。'
      }
    ]
  }
};
